{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)Написать приложение, которое собирает основные новости с сайтов mail.ru, lenta.ru, yandex.news\n",
    "Для парсинга использовать xpath. Структура данных должна содержать:\n",
    "* название источника,\n",
    "* наименование новости,\n",
    "* ссылку на новость,\n",
    "* дата публикации\n",
    "\n",
    "2)Сложить все новости в БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class News_parsing():\n",
    "    \n",
    "      \n",
    "    def get_news_info(self):\n",
    "        \n",
    "        self.main_page = requests.get(self.main_link, headers = self.headers_user_agent)\n",
    "        \n",
    "        links, dates, titles, sources = self._news_info(self.main_page, self.news_links_xpath)\n",
    "        \n",
    "        info_news = pd.DataFrame({'link':links, 'date':dates, 'title':titles, 'source':sources})\n",
    "        \n",
    "        return info_news\n",
    "        \n",
    "        \n",
    "    def _news_link(self, main_page, news_links_xpath):\n",
    "        news_href = html.fromstring(main_page.text).xpath(self.news_links_xpath)\n",
    "        \n",
    "        return news_href\n",
    "        \n",
    "        \n",
    "    def _news_info(self, main_page, news_links_xpath):\n",
    "        \n",
    "        links = self._news_link(self.main_page, self.news_links_xpath)\n",
    "        \n",
    "        dates = []\n",
    "        titles = []\n",
    "        sources = []\n",
    "        \n",
    "        \n",
    "        for link in links:\n",
    "            page = html.fromstring(requests.get(link, headers = self.headers_user_agent).text)\n",
    "            \n",
    "            date = page.xpath(self.news_date_xpath)\n",
    "            title = page.xpath(self.news_title_xpath)\n",
    "            \n",
    "            source = self.news_source_xpath\n",
    "            if source[0] == '/':\n",
    "                source = page.xpath(self.news_source_xpath)\n",
    "                sources.append(source[0])\n",
    "            else:\n",
    "                sources.append(source)\n",
    "            date = self._date_formetter(date)\n",
    "            title = [''.join(title).replace('\\xa0', ' ')]\n",
    "\n",
    "            dates.append(date[0])\n",
    "            titles.append(title[0])\n",
    "        \n",
    "        return links, dates, titles, sources\n",
    "    \n",
    "    \n",
    "    def _date_formetter(self, date):\n",
    "        date = ''.join(list(map(lambda x: x.split('T')[0], date))).split('-')[::-1]\n",
    "        date = ['.'.join(date)]\n",
    "        return date\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mail_news(News_parsing):\n",
    "    def __init__(self):\n",
    "        self.headers_user_agent = {'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'}\n",
    "    \n",
    "        self.main_link = 'https://mail.ru/'\n",
    "        \n",
    "        self.news_links_xpath = \"//div[@class='news-item i-fade-white i-fade-full i-nowrap news-item_inline']//a[not(@class='news-item__label i-color-black i-inline')]/@href\"\n",
    "        \n",
    "        self.news_date_xpath = \"//span[@class='note__text breadcrumbs__text js-ago']/@datetime | //div[@class='breadcrumbs breadcrumbs_article']/span[1]/@datetime\"\n",
    "        self.news_title_xpath = \"//div[@class='hdr__wrapper']/span[@class='hdr__text']/h1[@class='hdr__inner']/text() | //div[@class='p-intro__caption']/h1[@class='p-intro__title']/text()\"\n",
    "        self.news_source_xpath = \"//a[@class='link color_gray breadcrumbs__link']/span/text()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenta_news(News_parsing):\n",
    "    def __init__(self):\n",
    "        self.headers_user_agent = {'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'}\n",
    "    \n",
    "        self.main_link = 'https://lenta.ru'\n",
    "        \n",
    "        self.news_links_xpath = \"//div[contains(@class, 'js-main__content') and contains(@class, 'span8')]//div[contains(@class, 'span4')]//time[@class='g-time']/parent::*/@href\"\n",
    "        self.news_links_xpath += \" | \"\n",
    "        self.news_links_xpath += \"//div[contains(@class, 'js-content') and contains(@class, 'row')][1]//div[contains(@class, 'span4')]//a[contains(@class, 'js-dh')]/@href\"\n",
    "        self.news_links_xpath += \" | \"\n",
    "        self.news_links_xpath += \"//div[contains(@class, 'js-content') and contains(@class, 'row')][2]//div[contains(@class, 'span4')]//div[contains(@class, 'item') and contains(@class, 'news')]//div[contains(@class, 'title')]//a/@href\"\n",
    "        \n",
    "        self.news_date_xpath = \"//div[contains(@class, 'js-topic__header')]//div[contains(@class, 'b-topic__info')]//time[@class='g-date']/@datetime\"\n",
    "        self.news_title_xpath = \"//div[contains(@class, 'b-topic__header')]//h1[contains(@class, 'b-topic__title')]/text() | //div[contains(@class, 'premial-header__title')]/text()\"\n",
    "        \n",
    "        self.news_source_xpath = \"Lenta.ru\"\n",
    "        \n",
    "        \n",
    "    def _news_link(self, main_page, news_links_xpath):\n",
    "        news_href = html.fromstring(main_page.text).xpath(self.news_links_xpath)\n",
    "        \n",
    "        def __temp_link(x):\n",
    "            if re.search(r'^(\\/news).+', x): \n",
    "                x = self.main_link + x\n",
    "            else:\n",
    "                x = None\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        return list(filter(None, map(lambda x: __temp_link(x), news_href)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yandex_news(News_parsing):\n",
    "    def __init__(self):\n",
    "        self.headers_user_agent = {'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36'}\n",
    "    \n",
    "        self.main_link = 'https://yandex.ru/news/'\n",
    "        \n",
    "        self.news_links_xpath = \"//div[@class='stories-set__main-item']//h2[@class='story__title']//a/@href\"\n",
    "        self.news_links_xpath += \" | \"\n",
    "        self.news_links_xpath += \"//table[@class='stories-set__items']//td[@class='stories-set__item']//h2[@class='story__title']//a/@href\"\n",
    "       \n",
    "        self.news_date_xpath = \"//div[@class='stories-set__main-item']//div[@class='story__date']/text()\"\n",
    "        self.news_date_xpath += \" | \"\n",
    "        self.news_date_xpath += \"//table[@class='stories-set__items']//td[@class='stories-set__item']//div[@class='story__date']/text()\"\n",
    "        \n",
    "        \n",
    "        self.news_title_xpath = \"//div[@class='stories-set__main-item']//h2[@class='story__title']//a/text()\"\n",
    "        self.news_title_xpath += \" | \"\n",
    "        self.news_title_xpath += \"//table[@class='stories-set__items']//td[@class='stories-set__item']//h2[@class='story__title']//a/text()\"\n",
    "        \n",
    "        \n",
    "        self.news_source_xpath = self.news_date_xpath\n",
    "        \n",
    "        \n",
    "    def _news_link(self, main_page, news_links_xpath):\n",
    "        news_href = html.fromstring(main_page.text).xpath(news_links_xpath)\n",
    "        \n",
    "        def __temp_link(x):\n",
    "            if re.search(r'^(\\/).+', x): \n",
    "                x = 'https://yandex.ru' + x\n",
    "                \n",
    "            return x\n",
    "        \n",
    "        \n",
    "        return list(filter(None, map(lambda x: __temp_link(x), news_href)))\n",
    "        \n",
    "        \n",
    "    def _get_date_title(self, main_page, link_xpath):\n",
    "        date_or_title = html.fromstring(main_page.text).xpath(link_xpath)\n",
    "        \n",
    "                \n",
    "        return date_or_title\n",
    "    \n",
    "    def _news_info(self, main_page, news_links_xpath):\n",
    "        \n",
    "        links = self._news_link(self.main_page, self.news_links_xpath)\n",
    "        \n",
    "        \n",
    "        months={'января':'01', \n",
    "                'февраля':'02', \n",
    "                'марта':'03', \n",
    "                'апреля':'04', \n",
    "                'мая':'05', \n",
    "                'июня':'06', \n",
    "                'июля':'07', \n",
    "                'августа':'08', \n",
    "                'сентября':'09', \n",
    "                'октября':'10', \n",
    "                'ноября':'11', \n",
    "                'декабря':'12'}\n",
    "        yesterday='вчера'\n",
    "        postyesterday='позавчера'\n",
    "        \n",
    "        def __temp_date(date):\n",
    "            if '\\xa0' not in date:\n",
    "                date = list(dt.today().timetuple())[0:3]\n",
    "                date[1] = str(date[1]).rjust(2, '0')\n",
    "                date = '.'.join(map(str,date[::-1]))\n",
    "            else:\n",
    "                date = ' '.join(date.split('\\xa0')).split(' ')\n",
    "                for i, s in enumerate(date):\n",
    "                    if s in months.keys():\n",
    "                        d = date[i-1]\n",
    "                        m = months[s]\n",
    "                        y = list(dt.today().timetuple())[0]\n",
    "                        date='.'.join([d,m,y])\n",
    "                    elif s == yesterday:\n",
    "                        date=list(dt.fromordinal(dt.toordinal(dt.today())-1).timetuple())[0:3]\n",
    "                        date[1] = str(date[1]).rjust(2, '0')\n",
    "                        date = '.'.join(map(str,date[::-1]))\n",
    "                    elif s == postyesterday:\n",
    "                        date=list(dt.fromordinal(dt.toordinal(dt.today())-2).timetuple())[0:3]\n",
    "                        date[1] = str(date[1]).rjust(2, '0')\n",
    "                        date = '.'.join(map(str,date[::-1]))\n",
    "                        \n",
    "            return date\n",
    "        \n",
    "        \n",
    "        def __temp_source(date):\n",
    "            \n",
    "            date = ' '.join(date.split('\\xa0')).split(' ')\n",
    "            \n",
    "            if '\\xa0' not in date and yesterday not in date and postyesterday not in date:\n",
    "                source = ' '.join(map(str,date[:-1:]))\n",
    "            else:\n",
    "                for i, s in enumerate(date):\n",
    "                    if s in months.keys():\n",
    "                        source = ' '.join(map(str,date[:i-1:]))\n",
    "                    elif s == yesterday or s == postyesterday:\n",
    "                        source = ' '.join(map(str,date[:i:]))\n",
    "                    \n",
    "                        \n",
    "            return source\n",
    "                \n",
    "        dates = list(map(lambda x: __temp_date(x), self._get_date_title(self.main_page, self.news_date_xpath)))\n",
    "        titles = self._get_date_title(self.main_page, self.news_title_xpath)\n",
    "        sources = list(map(lambda x: __temp_source(x), self._get_date_title(self.main_page, self.news_source_xpath)))\n",
    "        \n",
    "\n",
    "        return links, dates, titles, sources\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_mail = Mail_news()\n",
    "info_mail = news_mail.get_news_info()\n",
    "\n",
    "news_lenta = Lenta_news()\n",
    "info_lenta = news_lenta.get_news_info()\n",
    "\n",
    "news_yandex = Yandex_news()\n",
    "info_yandex = news_yandex.get_news_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = info_mail.copy()\n",
    "news = news.merge(info_lenta, how='outer')\n",
    "news = news.merge(info_yandex, how='outer')\n",
    "news_for_db = news.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "parsing_news = client['parsing_news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new in news_for_db:\n",
    "    try:\n",
    "        parsing_news.news.update_one({'link':new['link']}, {'$set':new}, upsert=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsing_news.news.count_documents({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
