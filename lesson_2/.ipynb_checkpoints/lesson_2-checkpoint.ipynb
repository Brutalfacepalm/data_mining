{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import time\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import re\n",
    "import json\n",
    "import xml.dom.minidom as minidom\n",
    "pd.options.display.max_rows = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо собрать информацию о вакансиях на вводимую должность (используем input или\n",
    "через аргументы) с сайта *superjob.ru* и *hh.ru*. Приложение должно анализировать несколько страниц\n",
    "сайта(также вводим через input или аргументы). Получившийся список должен содержать в себе\n",
    "минимум:\n",
    " - Наименование вакансии\n",
    " - Предлагаемую зарплату (отдельно мин. и и отдельно макс.)\n",
    " - Ссылку на саму вакансию\n",
    " - Сайт откуда собрана вакансия\n",
    "\n",
    "По своему желанию можно добавить еще работодателя и расположение. Данная структура должна\n",
    "быть одинаковая для вакансий с обоих сайтов. Общий результат можно вывести с помощью\n",
    "dataFrame через pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Parsing_HH():\n",
    "    \n",
    "    \n",
    "    def __init__(self, text, input_pages):\n",
    "        \n",
    "        self.headers = {'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "                                AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "                                Chrome/78.0.3904.108 Safari/537.36'}\n",
    "#         Атрибуты для парсинга\n",
    "        self.main_link = 'https://saratov.hh.ru/search/vacancy?L_is_autosearch=false&clusters=true&enable_snippets=true&items_on_page=20&text='\n",
    "        self.title_findAll_attrs = ['h1', {'class':'header','data-qa':'page-title'}]\n",
    "        self.current_page_find_attrs = ['div',{'class':'vacancy-serp'}]\n",
    "        self.items_find_attrs = ['div',{'class':'vacancy-serp-item'}]\n",
    "        self.pagers_1_find_attrs = ['div',{'data-qa':'pager-block'}]\n",
    "        self.pagers_2_find_attrs = ['a',{'data-qa':'pager-page'}]\n",
    "        self.name_find_attrs = ['a', {'data-qa':'vacancy-serp__vacancy-title'}]\n",
    "        self.href_main = ''\n",
    "        self.compensation_find_attrs = ['div', {'data-qa':'vacancy-serp__vacancy-compensation'}]\n",
    "        self.company_find_attrs = ['a', {'data-qa':'vacancy-serp__vacancy-employer'}]\n",
    "        self.city_find_attrs = ['span', {'data-qa':'vacancy-serp__vacancy-address'}]\n",
    "        self.title_NaN = f'По запросу «{text}» ничего не найдено'\n",
    "        self.source = 'HeadHunter'\n",
    "#         Входные данные\n",
    "        self.text = '+'.join(text.split())\n",
    "        self.input_pages = input_pages\n",
    "        \n",
    "#         Получим курсы валют с ЦБ РФ\n",
    "    def get_cbrf(self):\n",
    "        link_cbrf = 'http://www.cbr.ru/scripts/XML_daily.asp'\n",
    "        resp_cbrf = requests.get(link_cbrf, headers = self.headers).text\n",
    "        parsing_cbrf = minidom.parseString(resp_cbrf)\n",
    "        \n",
    "        currency = list(map(lambda x: x.childNodes[0].nodeValue, parsing_cbrf.getElementsByTagName('CharCode')))\n",
    "        course = list(map(lambda x: float(x.childNodes[0].nodeValue.replace(',','.')), parsing_cbrf.getElementsByTagName('Value')))\n",
    "        courses_cbrf = dict(zip(currency, course))\n",
    "        courses_cbrf['RUR']=1\n",
    "        \n",
    "        return courses_cbrf\n",
    "    \n",
    "#     Сформируем текст для поиска в адресную строку\n",
    "    def __text_get(self, text):\n",
    "        text = '+'.join(text.split())\n",
    "        \n",
    "        return text\n",
    "    \n",
    "#     Парсинг HTML по заданному адресу link\n",
    "    def __html_parsed(self, link):\n",
    "        response = requests.get(link, headers = self.headers)\n",
    "        if response.status_code != 200:\n",
    "            print(response.status_code)\n",
    "            return 'Ошибка GET запроса'\n",
    "        else:\n",
    "            parsed = bs(response.text, 'lxml')\n",
    "            return parsed\n",
    "    \n",
    "#     Сбор информации о результатах поиска\n",
    "    def __title(self, html_parsed):\n",
    "        title = html_parsed.findAll(*self.title_findAll_attrs)\n",
    "        title = title[0].get_text().replace('\\xa0', ' ')\n",
    "        \n",
    "        return title\n",
    "        \n",
    "                \n",
    "#     Получение блока с данными на текущей странице\n",
    "    def __parsed_current_items_block(self, html_parsed):\n",
    "        current_page = html_parsed.find(*self.current_page_find_attrs)\n",
    "        \n",
    "        return current_page\n",
    "        \n",
    "#     Получиение списка элементов для дальнейшего парсинга\n",
    "    def __get_items(self, current_page):\n",
    "        items = current_page.findAll(*self.items_find_attrs)\n",
    "        \n",
    "        return items\n",
    "        \n",
    "#     Получение количества страниц результатов поиска\n",
    "    def _pages(self, html_parsed):\n",
    "        pagers = html_parsed.findAll(*self.pagers_1_find_attrs)\n",
    "        \n",
    "        if pagers:\n",
    "            pagers = pagers[0].findAll(*self.pagers_2_find_attrs)\n",
    "            p = list(map(lambda x: x.get_text(), pagers))\n",
    "            p = list(map(int, filter(lambda x: re.match(r'\\d+', x), p)))\n",
    "                \n",
    "            return range(min([max(p), self.input_pages]))\n",
    "        else:\n",
    "            return [0]\n",
    "    \n",
    "#     Получение названия каждого элемента\n",
    "    def _get_name(self, names, hrefs, item):\n",
    "        \n",
    "        name = item.find(*self.name_find_attrs)\n",
    "        if name:\n",
    "            names.append(name.get_text())\n",
    "        else:\n",
    "            names.append('NaN')\n",
    "        href = name['href']\n",
    "        hrefs.append(href)\n",
    "    \n",
    "#     Получение курса конкретной валюты\n",
    "    def __get_course(self, courses, currency):\n",
    "        code =  {   \"USD\": \"USD\",\n",
    "                    \"AZN\": \"AZN\",\n",
    "                    \"KZT\": \"KZT\",\n",
    "                   \"грн.\": \"UAH\",\n",
    "              \"бел. руб.\": \"BYR\",\n",
    "                   \"руб.\": \"RUR\",\n",
    "                      '₽': \"RUR\",\n",
    "                    \"EUR\": \"EUR\",}\n",
    "                \n",
    "        course = courses[code[currency]]\n",
    "        \n",
    "        return course\n",
    "    \n",
    "    \n",
    "#     Разбор зарплаты на минимальную и максимальную\n",
    "    def __max_min_compensation(self, courses, compensation):\n",
    "        max_min = ''.join(compensation.get_text().split()[:-1:])\n",
    "        currency = compensation.get_text().split()[-1]\n",
    "        \n",
    "        course = self.__get_course(courses, currency)\n",
    "        \n",
    "        \n",
    "        down = re.match(r'от', max_min)\n",
    "        up = re.match(r'до', max_min)\n",
    "        \n",
    "        max_min = re.findall(r'\\d+', max_min)\n",
    "        max_min = list(map(int, max_min))\n",
    "        \n",
    "        if currency != 'руб.':\n",
    "            max_min = list(map(lambda x: x*course, max_min))\n",
    "            \n",
    "        if len(max_min) > 1:\n",
    "            max_compensation = max(max_min)\n",
    "            min_compensation = min(max_min)\n",
    "        else:\n",
    "            if down:\n",
    "                min_compensation = max_min[0]\n",
    "                max_compensation = 'NaN'\n",
    "            elif up:\n",
    "                min_compensation = 'NaN'\n",
    "                max_compensation = max_min[0]\n",
    "            elif not down and not up:\n",
    "                max_compensation = max_min[0]\n",
    "                min_compensation = max_min[0]\n",
    "            \n",
    "        return min_compensation, max_compensation\n",
    "    \n",
    "#     Получение информации о зарплате\n",
    "    def __get_compensation(self, min_compensation, max_compensation, item, courses):\n",
    "\n",
    "        compensation = item.find(*self.compensation_find_attrs)\n",
    "               \n",
    "        if compensation and re.match(r'\\d+', compensation.get_text()):\n",
    "            min_c, max_c = self.__max_min_compensation(courses, compensation)\n",
    "        else:\n",
    "            min_c, max_c = 'NaN', 'NaN'\n",
    "        \n",
    "        min_compensation.append(min_c)\n",
    "        max_compensation.append(max_c)\n",
    "           \n",
    "#     Получение информации о компании\n",
    "    def __get_company(self, companies, item):\n",
    "\n",
    "        company = item.find(*self.company_find_attrs)\n",
    "        if company:\n",
    "            companies.append(company.get_text())\n",
    "        else:\n",
    "            companies.append('NaN')\n",
    "    \n",
    "#     Получение информации о городе вакансии\n",
    "    def _get_city(self, cities, item):\n",
    "\n",
    "        city = item.find(*self.city_find_attrs)\n",
    "        if city:\n",
    "            cities.append(city.get_text().split(',')[0])\n",
    "        else:\n",
    "            cities.append('NaN')\n",
    "    \n",
    "    \n",
    "    def search(self):\n",
    "#         Получаем текст для поиска, запускаем поиск, парсим и смотрим на результаты поиска\n",
    "        text = self.text\n",
    "        html_parsed = self.__html_parsed(self.main_link + text)\n",
    "        title = self.__title(html_parsed)\n",
    "#         Формируем список страниц от 0 до заданного значения или максимальных результатов поиска, смотря что меньше\n",
    "        pages = self._pages(html_parsed)\n",
    "#         Запросим курсы всех валют с сайта ЦБ РФ\n",
    "        courses = self.get_cbrf()\n",
    "\n",
    "        names = []\n",
    "        min_compensation = []\n",
    "        max_compensation = []\n",
    "        hrefs = []\n",
    "        sources = []\n",
    "        companies = []\n",
    "        cities = []\n",
    "        \n",
    "#         Если поиск дал результаты, то:\n",
    "        if title != self.title_NaN:\n",
    "            for i in pages:\n",
    "#         Парсим каждую страницу отдельно, получаем блок элементов и затем список элементов\n",
    "                link = self.main_link + text + f'&page={i}'\n",
    "                html_parsed = self.__html_parsed(link)\n",
    "                current_items_block = self.__parsed_current_items_block(html_parsed)\n",
    "                \n",
    "                \n",
    "                items = self.__get_items(current_items_block)\n",
    "          \n",
    "                for item in items:\n",
    "#         Находим название вакансии, минимальную и максимальную зарплаты, название компании, город и сайт, откуда собрана инфа\n",
    "                    self._get_name(names, hrefs, item)\n",
    "                    self.__get_compensation(min_compensation, max_compensation, item, courses)                    \n",
    "                    self.__get_company(companies, item)\n",
    "                    self._get_city(cities, item)\n",
    "                    sources.append(self.source)\n",
    "#         Складываем всю информацию в соответсвующие списки - будущие столбцы датафрейма\n",
    "        \n",
    "            vacancies = {'Название вакансии':names, \n",
    "                         'Ссылка':hrefs, \n",
    "                         'Минимальная зарплата':min_compensation, \n",
    "                         'Максимальная зарплата':max_compensation, \n",
    "                         'Площадка': sources, \n",
    "                         'Компания': companies, \n",
    "                         'Город': cities}\n",
    "#         Формируем датафрейм для сайта, из словаря\n",
    "            df = pd.DataFrame(vacancies)\n",
    "            return df\n",
    "        else:\n",
    "            print(f'На сайте {self.source} {self.title_NaN}')\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parsing_SJ(Parsing_HH):\n",
    "    \n",
    "    \n",
    "    def __init__(self, text, input_pages):\n",
    "        self.headers = {'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "                                AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "                                Chrome/78.0.3904.108 Safari/537.36'}\n",
    "\n",
    "        self.text = '%20'.join(text.split())\n",
    "        \n",
    "        self.main_link = 'https://www.superjob.ru/vacancy/search/?geo%5Bc%5D%5B0%5D=1&keywords='\n",
    "         \n",
    "        self.title_findAll_attrs = ['span', {'class':['_3mfro _1ZlLP _2JVkc _2VHxz', '_3mfro _1hP6a _2JVkc _2VHxz']}]\n",
    "        \n",
    "        self.current_page_find_attrs = ['div',{'class':'_1Ttd8 _2CsQi'}]\n",
    "        \n",
    "        self.items_find_attrs = ['div',{'class':'_3syPg _3P0J7 _9_FPy'}]\n",
    "        \n",
    "        self.pagers_1_find_attrs = ['div',{'class':'L1p51'}]\n",
    "        self.pagers_2_find_attrs = ['span',{'class':'_23m0W'}]\n",
    "        \n",
    "        self.name_find_attrs = ['div', {'class':'_3mfro CuJz5 PlM3e _2JVkc _3LJqf'}]\n",
    "        self.href_main = 'https://www.superjob.ru'\n",
    "        self.compensation_find_attrs = ['span', {'class':'_3mfro _2Wp8I f-test-text-company-item-salary PlM3e _2JVkc _2VHxz'}]\n",
    "        self.company_find_attrs = ['a', {'class':'Vm5jz'}]\n",
    "        self.city_find_attrs = ['span', {'class':'_3mfro f-test-text-company-item-location _9fXTd _2JVkc _3e53o'}]\n",
    "        \n",
    "        self.title_NaN = 'Вакансий не найдено'\n",
    "        self.source = 'SuperJob'\n",
    "        self.input_pages = input_pages\n",
    "        \n",
    "            \n",
    "            \n",
    "#     Переопределяем поиск названия и ссылки для SuperJob, так как структура сайта отличается от HeadHunter\n",
    "    def _get_name(self, names, hrefs, item):\n",
    "        \n",
    "        name = item.find(*self.name_find_attrs)\n",
    "        if name:\n",
    "            names.append(name.get_text())\n",
    "        else:\n",
    "            names.append('NaN')\n",
    "        \n",
    "        href = self.href_main + name.find_parent('div').findChild('a')['href']\n",
    "        \n",
    "        hrefs.append(href)\n",
    "        \n",
    "            \n",
    "#     Нумерация страниц на SuperJob отличается от HeadHunter. На SJ начинается с 1, на HH с 0\n",
    "    def _pages(self, html_parsed):\n",
    "        pagers = html_parsed.findAll(*self.pagers_1_find_attrs)\n",
    "        \n",
    "        if pagers:\n",
    "            pagers = pagers[0].findAll(*self.pagers_2_find_attrs)\n",
    "            p = list(map(lambda x: x.get_text(), pagers))\n",
    "            p = list(map(int, filter(lambda x: re.match(r'\\d+', x), p)))\n",
    "                \n",
    "            return range(1, min([max(p), self.input_pages])+1)\n",
    "        else:\n",
    "            return [1]\n",
    "    \n",
    "#     Переопределяем поиск города, т.к. на SJ название города стоит в середине блока или в конце, а на HH в начале\n",
    "    def _get_city(self, cities, item):\n",
    "\n",
    "        city = item.find(*self.city_find_attrs)\n",
    "        if city:\n",
    "            cities.append(city.findChildren('span')[1].get_text().split(',')[0].split(' ')[0])\n",
    "        else:\n",
    "            cities.append('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите название вакансии для поиска: python\n",
      "Введите максимальное количество страниц поиска: 10\n"
     ]
    }
   ],
   "source": [
    "text =input('Введите название вакансии для поиска: ')\n",
    "input_pages =int(input('Введите максимальное количество страниц поиска: '))\n",
    "hh = Parsing_HH(text, input_pages)\n",
    "sj = Parsing_SJ(text, input_pages)\n",
    "\n",
    "df_hh = hh.search()\n",
    "df_sj = sj.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vacancy = pd.concat([df_hh, df_sj], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Название вакансии</th>\n",
       "      <th>Ссылка</th>\n",
       "      <th>Минимальная зарплата</th>\n",
       "      <th>Максимальная зарплата</th>\n",
       "      <th>Площадка</th>\n",
       "      <th>Компания</th>\n",
       "      <th>Город</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Программист Python</td>\n",
       "      <td>https://saratov.hh.ru/vacancy/35005466?query=p...</td>\n",
       "      <td>75000</td>\n",
       "      <td>120000</td>\n",
       "      <td>HeadHunter</td>\n",
       "      <td>ООО Тензор</td>\n",
       "      <td>Тюмень</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://saratov.hh.ru/vacancy/35011897?query=p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HeadHunter</td>\n",
       "      <td>HeadHunter::Analytics/Data Science</td>\n",
       "      <td>Москва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Developer</td>\n",
       "      <td>https://saratov.hh.ru/vacancy/34635965?query=p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HeadHunter</td>\n",
       "      <td>Emerline</td>\n",
       "      <td>Минск</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ведущий разработчик Python / Software developm...</td>\n",
       "      <td>https://saratov.hh.ru/vacancy/34200113?query=p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HeadHunter</td>\n",
       "      <td>CATAPULTO.RU</td>\n",
       "      <td>Москва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst (Senior)</td>\n",
       "      <td>https://saratov.hh.ru/vacancy/33864288?query=p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HeadHunter</td>\n",
       "      <td>Сбербанк для экспертов</td>\n",
       "      <td>Москва</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Название вакансии  \\\n",
       "0                                 Программист Python   \n",
       "1                                     Data Scientist   \n",
       "2                                   Python Developer   \n",
       "3  Ведущий разработчик Python / Software developm...   \n",
       "4                              Data Analyst (Senior)   \n",
       "\n",
       "                                              Ссылка Минимальная зарплата  \\\n",
       "0  https://saratov.hh.ru/vacancy/35005466?query=p...                75000   \n",
       "1  https://saratov.hh.ru/vacancy/35011897?query=p...                  NaN   \n",
       "2  https://saratov.hh.ru/vacancy/34635965?query=p...                  NaN   \n",
       "3  https://saratov.hh.ru/vacancy/34200113?query=p...                  NaN   \n",
       "4  https://saratov.hh.ru/vacancy/33864288?query=p...                  NaN   \n",
       "\n",
       "  Максимальная зарплата    Площадка                             Компания  \\\n",
       "0                120000  HeadHunter                           ООО Тензор   \n",
       "1                   NaN  HeadHunter   HeadHunter::Analytics/Data Science   \n",
       "2                   NaN  HeadHunter                             Emerline   \n",
       "3                   NaN  HeadHunter                         CATAPULTO.RU   \n",
       "4                   NaN  HeadHunter               Сбербанк для экспертов   \n",
       "\n",
       "    Город  \n",
       "0  Тюмень  \n",
       "1  Москва  \n",
       "2   Минск  \n",
       "3  Москва  \n",
       "4  Москва  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vacancy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Название вакансии</th>\n",
       "      <th>Ссылка</th>\n",
       "      <th>Минимальная зарплата</th>\n",
       "      <th>Максимальная зарплата</th>\n",
       "      <th>Площадка</th>\n",
       "      <th>Компания</th>\n",
       "      <th>Город</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>184</td>\n",
       "      <td>274</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>230</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Программист Python</td>\n",
       "      <td>https://saratov.hh.ru/vacancy/34868863?query=p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HeadHunter</td>\n",
       "      <td>Филиал ФКУ «Налог-Сервис» ФНС России по ЦОД в ...</td>\n",
       "      <td>Москва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Название вакансии                                             Ссылка  \\\n",
       "count                  274                                                274   \n",
       "unique                 184                                                274   \n",
       "top     Программист Python  https://saratov.hh.ru/vacancy/34868863?query=p...   \n",
       "freq                    14                                                  1   \n",
       "\n",
       "       Минимальная зарплата Максимальная зарплата    Площадка  \\\n",
       "count                   274                   274         274   \n",
       "unique                   28                    28           2   \n",
       "top                     NaN                   NaN  HeadHunter   \n",
       "freq                    193                   193         200   \n",
       "\n",
       "                                                 Компания   Город  \n",
       "count                                                 274     274  \n",
       "unique                                                230      50  \n",
       "top     Филиал ФКУ «Налог-Сервис» ФНС России по ЦОД в ...  Москва  \n",
       "freq                                                    4     117  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vacancy.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
